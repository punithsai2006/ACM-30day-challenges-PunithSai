{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905850fc-0c51-490b-9f8b-4490ab9eb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# To clean up warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85a6b7c6-fe09-4238-8aa4-fb5e3704365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 32)\n",
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "Target Distribution:\n",
      "diagnosis\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2.Load and Inspect Data\n",
    "df = pd.read_csv(\"C:/Users/punit/OneDrive/Desktop/ACM-30Days/breast-cancer.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Map target variable\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Drop ID column if exists\n",
    "if 'id' in df.columns:\n",
    "    df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(df['diagnosis'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a430a792-53e5-440f-8131-97ae6ab0b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Preprocess (Train/Test Split & Scaling)\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42, test_size=0.2\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2478ce23-1e7f-425e-bf7b-e5e2d2181e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      " Accuracy: 0.9737\n",
      " Confusion Matrix:\n",
      " [[72  0]\n",
      " [ 3 39]]\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "=== AdaBoost ===\n",
      " Accuracy: 0.9825\n",
      " Confusion Matrix:\n",
      " [[72  0]\n",
      " [ 2 40]]\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        72\n",
      "           1       1.00      0.95      0.98        42\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      " Accuracy: 0.9737\n",
      " Confusion Matrix:\n",
      " [[72  0]\n",
      " [ 3 39]]\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.Train & Evaluate Models\n",
    "# Define Models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(algorithm='SAMME', random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store accuracy\n",
    "results = {}\n",
    "\n",
    "# Train each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\" Accuracy: {acc:.4f}\")\n",
    "    print(\" Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\" Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a914d8e4-bb69-4bdf-8fbd-72dec8ee3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_32e5b_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32e5b_row1_col1, #T_32e5b_row2_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_32e5b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_32e5b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_32e5b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_32e5b_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_32e5b_row0_col0\" class=\"data row0 col0\" >AdaBoost</td>\n",
       "      <td id=\"T_32e5b_row0_col1\" class=\"data row0 col1\" >0.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32e5b_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "      <td id=\"T_32e5b_row1_col0\" class=\"data row1 col0\" >Random Forest</td>\n",
       "      <td id=\"T_32e5b_row1_col1\" class=\"data row1 col1\" >0.9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32e5b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_32e5b_row2_col0\" class=\"data row2 col0\" >XGBoost</td>\n",
       "      <td id=\"T_32e5b_row2_col1\" class=\"data row2 col1\" >0.9737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22b28f8df70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5: Comparison Table\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame(list(results.items()), columns=[\"Model\", \"Accuracy\"])\n",
    "comparison.sort_values(by=\"Accuracy\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"Final Model Comparison:\")\n",
    "display(comparison.style.background_gradient(cmap='Blues').format({\"Accuracy\": \"{:.4f}\"}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
